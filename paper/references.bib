@article{Adcock1988,
  title = {A Bayesian Approach to Calculating Sample Sizes},
  volume = {37},
  ISSN = {0039-0526},
  url = {http://dx.doi.org/10.2307/2348770},
  DOI = {10.2307/2348770},
  number = {4/5},
  journal = {The Statistician},
  publisher = {JSTOR},
  author = {Adcock,  C. J.},
  year = {1988},
  pages = {433}
}

@article{Lindley1997,
  title = {The choice of sample size},
  volume = {46},
  ISSN = {1467-9884},
  url = {http://dx.doi.org/10.1111/1467-9884.00068},
  DOI = {10.1111/1467-9884.00068},
  number = {2},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  publisher = {Wiley},
  author = {Lindley,  Dennis V.},
  year = {1997},
  month = jul,
  pages = {129–138}
}

@article{Grabovoy2022,
  title = {Numerical Methods of Sufficient Sample Size Estimation for Generalised Linear Models},
  volume = {43},
  ISSN = {1818-9962},
  url = {http://dx.doi.org/10.1134/S1995080222120125},
  DOI = {10.1134/s1995080222120125},
  number = {9},
  journal = {Lobachevskii Journal of Mathematics},
  publisher = {Pleiades Publishing Ltd},
  author = {Grabovoy,  A. V. and Gadaev,  T. T. and Motrenko,  A. P. and Strijov,  V. V.},
  year = {2022},
  month = sep,
  pages = {2453–2462}
}

@article{Joseph1995,
 ISSN = {00390526, 14679884},
 URL = {http://www.jstor.org/stable/2348439},
 abstract = {Three different Bayesian approaches to sample size calculations based on highest posterior density (HPD) intervals are discussed and illustrated in the context of a binomial experiment. The preposterior marginal distribution of the data is used to find the sample size needed to attain an expected HPD coverage probability for a given fixed interval length. Alternatively, one can find the sample size required to attain an expected HPD interval length for a fixed coverage. These two criteria can lead to different sample size requirements. In addition to averaging, a worst possible outcome scenario is also considered. The results presented here provide an exact solution to a problem recently addressed in the literature.},
 author = {Lawrence Joseph and David B. Wolfson and Roxane Du Berger},
 journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
 number = {2},
 pages = {143--154},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Sample Size Calculations for Binomial Proportions via Highest Posterior Density Intervals},
 urldate = {2023-12-12},
 volume = {44},
 year = {1995}
}

@article{Joseph1997,
author = {Lawrence Joseph and Roxane Du Berger and Patrick Bélisle},
title = {BAYESIAN AND MIXED BAYESIAN/LIKELIHOOD CRITERIA FOR SAMPLE SIZE DETERMINATION},
journal = {Statistics in Medicine},
volume = {16},
number = {7},
pages = {769-781},
doi = {https://doi.org/10.1002/(SICI)1097-0258(19970415)16:7<769::AID-SIM495>3.0.CO;2-V},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819970415%2916%3A7%3C769%3A%3AAID-SIM495%3E3.0.CO%3B2-V},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291097-0258%2819970415%2916%3A7%3C769%3A%3AAID-SIM495%3E3.0.CO%3B2-V},
abstract = {Abstract Sample size estimation is a major component of the design of virtually every experiment in medicine. Prudent use of the available prior information is a crucial element of experimental planning. Most sample size formulae in current use employ this information only in the form of point estimates, even though it is usually more accurately expressed as a distribution over a range of values. In this paper, we review several Bayesian and mixed Bayesian/likelihood approaches to sample size calculations based on lengths and coverages of posterior credible intervals. We apply these approaches to the design of an experiment to estimate the difference between two binomial proportions, and we compare results to those derived from standard formulae. Consideration of several criteria can contribute to selection of a final sample size. © 1997 by John Wiley \& Sons, Ltd.},
year = {1997}
}

@article{MOTRENKO2014743,
	abstract = {The problem of sample size estimation is important in medical applications, especially in cases of expensive measurements of immune biomarkers. This paper describes the problem of logistic regression analysis with the sample size determination algorithms, namely the methods of univariate statistics, logistics regression, cross-validation and Bayesian inference. The authors, treating the regression model parameters as a multivariate variable, propose to estimate the sample size using the distance between parameter distribution functions on cross-validated data sets. Herewith, the authors give a new contribution to data mining and statistical learning, supported by applied mathematics.},
	author = {Anastasiya Motrenko and Vadim Strijov and Gerhard-Wilhelm Weber},
	doi = {https://doi.org/10.1016/j.cam.2013.06.031},
	issn = {0377-0427},
	journal = {Journal of Computational and Applied Mathematics},
	keywords = {Logistic regression, Sample size, Feature selection, Bayesian inference, Kullback--Leibler divergence},
	pages = {743-752},
	title = {Sample size determination for logistic regression},
	url = {https://www.sciencedirect.com/science/article/pii/S0377042713003294},
	volume = {255},
	year = {2014},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0377042713003294},
	bdsk-url-2 = {https://doi.org/10.1016/j.cam.2013.06.031}
}

@article{PhamGia1997,
  title = {On Bayesian analysis,  Bayesian decision theory and the sample size problem},
  volume = {46},
  ISSN = {1467-9884},
  url = {http://dx.doi.org/10.1111/1467-9884.00069},
  DOI = {10.1111/1467-9884.00069},
  number = {2},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  publisher = {Wiley},
  author = {Pham-Gia,  T.},
  year = {1997},
  month = jul,
  pages = {139–144}
}

@article{Gelfand2002,
  title = {A simulation-based approach to Bayesian sample size determination for performance under a given model and for separating models},
  volume = {17},
  ISSN = {0883-4237},
  url = {http://dx.doi.org/10.1214/ss/1030550861},
  DOI = {10.1214/ss/1030550861},
  number = {2},
  journal = {Statistical Science},
  publisher = {Institute of Mathematical Statistics},
  author = {Gelfand,  Alan E. and Wang,  Fei},
  year = {2002},
  month = may 
}

@article{Pezeshk2008,
  title = {The choice of sample size: a mixed Bayesian / frequentist approach},
  volume = {18},
  ISSN = {1477-0334},
  url = {http://dx.doi.org/10.1177/0962280208089298},
  DOI = {10.1177/0962280208089298},
  number = {2},
  journal = {Statistical Methods in Medical Research},
  publisher = {SAGE Publications},
  author = {Pezeshk,  Hamid and Nematollahi,  Nader and Maroufy,  Vahed and Gittins,  John},
  year = {2008},
  month = apr,
  pages = {183–194}
}

@article{Brutti2014,
  title = {Bayesian-frequentist sample size determination: a game of two priors},
  volume = {72},
  ISSN = {2281-695X},
  url = {http://dx.doi.org/10.1007/s40300-014-0043-2},
  DOI = {10.1007/s40300-014-0043-2},
  number = {2},
  journal = {METRON},
  publisher = {Springer Science and Business Media LLC},
  author = {Brutti,  Pierpaolo and De Santis,  Fulvio and Gubbiotti,  Stefania},
  year = {2014},
  month = may,
  pages = {133–151}
}

@article{Cao2009,
  title = {Comparison of Bayesian sample size criteria: ACC,  ALC,  and WOC},
  volume = {139},
  ISSN = {0378-3758},
  url = {http://dx.doi.org/10.1016/j.jspi.2009.05.041},
  DOI = {10.1016/j.jspi.2009.05.041},
  number = {12},
  journal = {Journal of Statistical Planning and Inference},
  publisher = {Elsevier BV},
  author = {Cao,  Jing and Lee,  J. Jack and Alber,  Susan},
  year = {2009},
  month = dec,
  pages = {4111–4122}
}

@misc{UCI,
  author = {Markelle, Kelly and Rachel, Longjohn and Kolby, Nottingham},
  title = {The UCI Machine Learning Repository},
  url = {https://archive.ics.uci.edu}
}


@article{Goldberg1988,
	author = {Goldberg, David E. and Holland, John H.},
	date = {1988/10/01},
	date-added = {2024-02-08 11:12:14 +0300},
	date-modified = {2024-02-08 11:12:14 +0300},
	doi = {10.1023/A:1022602019183},
	id = {Goldberg1988},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {2},
	pages = {95--99},
	title = {Genetic Algorithms and Machine Learning},
	url = {https://doi.org/10.1023/A:1022602019183},
	volume = {3},
	year = {1988},
	bdsk-url-1 = {https://doi.org/10.1023/A:1022602019183}}

@inbook{Mirjalili2019,
	abstract = {Genetic Algorithm (GA) is one of the first population-based stochastic algorithm proposed in the history. Similar to other EAs, the main operators of GA are selection, crossover, and mutation. This chapter briefly presents this algorithm and applies it to several case studies to observe its performance.},
	address = {Cham},
	author = {Mirjalili, Seyedali},
	booktitle = {Evolutionary Algorithms and Neural Networks: Theory and Applications},
	doi = {10.1007/978-3-319-93025-1_4},
	isbn = {978-3-319-93025-1},
	pages = {43--55},
	publisher = {Springer International Publishing},
	title = {Genetic Algorithm},
	url = {https://doi.org/10.1007/978-3-319-93025-1_4},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-93025-1_4}}

@inbook{Kramer2017,
	abstract = {Genetic Algorithms are heuristic search approaches that are applicable to a wide range of optimization problems. This flexibility makes them attractive for many optimization problems in practice. Evolution is the basis of Genetic Algorithms. The current variety and success of species is a good reason for believing in the power of evolution. Species are able to adapt to their environment. They have developed to complex structures that allow the survival in different kinds of environments. Mating and getting offspring to evolve belong to the main principles of the success of evolution. These are good reasons for adapting evolutionary principles to solving optimization problems.},
	address = {Cham},
	author = {Kramer, Oliver},
	booktitle = {Genetic Algorithm Essentials},
	doi = {10.1007/978-3-319-52156-5_2},
	isbn = {978-3-319-52156-5},
	pages = {11--19},
	publisher = {Springer International Publishing},
	title = {Genetic Algorithms},
	url = {https://doi.org/10.1007/978-3-319-52156-5_2},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-52156-5_2}}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@phdthesis{Aduenko2017,
    author = {Aduenko, Alexander},
    title = {Selection of multimodels in classification tasks},
    school = {MIPT},
    year = {2017},
    url = {https://www.frccsc.ru/diss-council/00207305/diss/list/aduenko\_aa}
}

@article{bies2006genetic,
  title={A genetic algorithm-based, hybrid machine learning approach to model selection},
  author={Bies, Robert R and Muldoon, Matthew F and Pollock, Bruce G and Manuck, Steven and Smith, Gwenn and Sale, Mark E},
  journal={Journal of pharmacokinetics and pharmacodynamics},
  volume={33},
  number={2},
  pages={195},
  year={2006},
  publisher={Springer Nature BV}
}

@article{cawley2010over,
  title={On over-fitting in model selection and subsequent selection bias in performance evaluation},
  author={Cawley, Gavin C and Talbot, Nicola LC},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={2079--2107},
  year={2010},
  publisher={JMLR. org}
}

@article{raschka2018model,
  title={Model evaluation, model selection, and algorithm selection in machine learning},
  author={Raschka, Sebastian},
  journal={arXiv preprint arXiv:1811.12808},
  year={2018}
}

@article{byrd2012sample,
  title={Sample size selection in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Nocedal, Jorge and Wu, Yuchen},
  journal={Mathematical programming},
  volume={134},
  number={1},
  pages={127--155},
  year={2012},
  publisher={Springer}
}

@article{figueroa2012predicting,
  title={Predicting sample size required for classification performance},
  author={Figueroa, Rosa L and Zeng-Treitler, Qing and Kandula, Sasikiran and Ngo, Long H},
  journal={BMC medical informatics and decision making},
  volume={12},
  pages={1--10},
  year={2012},
  publisher={Springer}
}

@article{self1988power,
  title={Power/sample size calculations for generalized linear models},
  author={Self, Steven G and Mauritsen, Robert H},
  journal={Biometrics},
  pages={79--86},
  year={1988},
  publisher={JSTOR}
}

@article{shieh2000power,
  title={On power and sample size calculations for likelihood ratio tests in generalized linear models},
  author={Shieh, Gwowen},
  journal={Biometrics},
  volume={56},
  number={4},
  pages={1192--1196},
  year={2000},
  publisher={Wiley Online Library}
}

@article{shieh2005power,
  title={On power and sample size calculations for Wald tests in generalized linear models},
  author={Shieh, Gwowen},
  journal={Journal of Statistical Planning and Inference},
  volume={128},
  number={1},
  pages={43--59},
  year={2005},
  publisher={Elsevier}
}

@article{balki2019sample,
  title={Sample-size determination methodologies for machine learning in medical imaging research: a systematic review},
  author={Balki, Indranil and Amirabadi, Afsaneh and Levman, Jacob and Martel, Anne L and Emersic, Ziga and Meden, Blaz and Garcia-Pedrero, Angel and Ramirez, Saul C and Kong, Dehan and Moody, Alan R and others},
  journal={Canadian Association of Radiologists Journal},
  volume={70},
  number={4},
  pages={344--353},
  year={2019},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}